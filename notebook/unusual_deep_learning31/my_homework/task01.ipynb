{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task01 绪论与深度学习概述、数学基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 绪论与深度学习概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 人工智能、机器学习与深度学习\n",
    "\n",
    "- 人工智能分类：强人工智能、弱人工智能、超级人工智能\n",
    "- 机器学习分类：有监督学习、无监督学习、强化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 起源与发展\n",
    "\n",
    "- 第1阶段：提出MP神经元模型、感知器、ADLINE神经网络，并指出感知器只能解决简单的线性分类任务，无法解决XOR简单分类问题\n",
    "- 第2阶段：提出Hopfiled神经网络、误差反向传播算法、CNN\n",
    "- 第3阶段：提出深度学习概念，在语音识别、图像识别的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 深度学习定义与分类\n",
    "- 定义：采用多层网络结构对未知数据进行分类或回归\n",
    "- 分类：\n",
    "  1. 有监督学习：深度前馈网络、卷积神经网络、循环神经网络等\n",
    "  2. 无监督学习：深度信念网、深度玻尔兹曼机、深度自编码器等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 主要应用\n",
    "\n",
    "- 图像处理领域：图像分类、物体检测、图像分割、图像回归\n",
    "- 语音识别领域：语音识别、声纹识别、语音合成\n",
    "- 自然语音处理领域：语言模型、情感分析、神经机器翻译、神经自动摘要、机器阅读理解、自然语言推理\n",
    "- 综合应用：图像描述、可视回答、图像生成、视频生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 数学基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 矩阵论\n",
    "\n",
    "- 张量：标量是0阶张量，矢量是1阶张量，矩阵是2阶张量，三维及以上数组称为张量\n",
    "- 矩阵的秩（Rank）：矩阵向量中的极大线性无关组的数目\n",
    "- 矩阵的逆：\n",
    "  1. 奇异矩阵：$rank(A_{n×n})<n$\n",
    "  2. 非奇异矩阵：$rank(A_{n×n})=n$\n",
    "- 广义逆矩阵：如果存在矩阵$B$使得$ABA=A$，则称$B$为$A$的广义逆矩阵\n",
    "- 矩阵分解：\n",
    "  1. 特征分解：$A = U\\Sigma U^{T}$\n",
    "  2. 奇异值分解：$A = U \\Sigma V^{T}$、$U^T U = V^T V = I$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 概率统计\n",
    "\n",
    "- 随机变量：\n",
    "  1. 分类：离散随机变量、连续随机变量\n",
    "  2. 概念：用概率分布来指定它的每个状态的可能性\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 常见的概率分布：\n",
    "  1. 伯努利分布：单个二值型离散随机变量的分布，概率分布函数：$P(X=1)=p,P(X=0)=1-p$\n",
    "  2. 二项分布：重复$n$次伯努利试验，概率分布函数：$P(X = k) = C_n^k p^k (1-p)^{n-k}$\n",
    "  3. 均匀分布：概率密度函数：$\\displaystyle p(x) = \\frac{1}{b-a}, \\quad a < x <b$\n",
    "  4. 高斯分布：又称正态分布，概率密度函数：$\\displaystyle p(x) = \\frac{1}{\\sqrt{2 \\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}$\n",
    "  5. 指数分布：独立随机事件发生的时间间隔，概率密度函数：$p(x) = \\lambda e^{-\\lambda x} (x \\geqslant 0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 多变量概率分布：\n",
    "  1. 条件概率：$P(X | Y)$\n",
    "  2. 联合概率：$P(X, Y)$\n",
    "  3. 先验概率：在事件发生前已知的概率\n",
    "  4. 后验概率：基于新的信息，修正后来的先验概率，获得更接近实际情况的概率估计\n",
    "  5. 全概率公式：$\\displaystyle P(B) = \\sum_{i = 1}^nP(A_i)P(B|A_i)$\n",
    "  6. 贝叶斯公式：\n",
    "  $$\n",
    "  P(A_i | B) \n",
    "  = \\frac{ P(B | A_i) P(A_i)}{P(B)} \n",
    "  = \\frac{P(B | A_i) P(A_i)} {\\displaystyle \\sum_{j=1}^{n} P(A_j) P(B | A_j)}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 常用统计量：\n",
    "  1. 方差：随机变量与数学期望之间的偏离程度\n",
    "  $\\text{Var}(X) = E\\left\\{ [x-E(x)]^2 \\right \\} = E( x^2 ) -[E(x)]^2$\n",
    "  2. 协方差：两个随机变量$X$和$Y$的总体误差\n",
    "  $\\text{Cov}(X,Y)=E\\left\\{ [x-E(x)][y-E(y)] \\right\\}=E \\left( xy \\right) - E(x)E(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 信息论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 熵：样本集纯度指标，或样本集报班的平均信息量\n",
    "$$H(X) = - \\sum_{i = 1}^n P(x_i) \\log_2 P(x_i)$$\n",
    "\n",
    "- 联合熵：度量二维随机变量$XY$的不确定性\n",
    "$$H(X, Y) = -\\sum_{i = 1}^n \\sum_{j = 1}^n P(x_i, y_j) \\log_2 P(x_i, y_j)$$\n",
    "\n",
    "- 条件熵：\n",
    "$$\\begin{aligned}\n",
    "H(Y|X) \n",
    "&= \\sum_{i = 1}^n P(x_i) H(Y|X = x_i) \\\\\n",
    "&= -\\sum_{i = 1}^n P(x_i) \\sum_{j = 1}^n P(y_j | x_i) \\log_2 P(y_j | x_i) \\\\\n",
    "&= -\\sum_{i = 1}^n \\sum_{j = 1}^n P(x_i, y_j) \\log_2 P(y_j | x_i)\n",
    "\\end{aligned}$$\n",
    "\n",
    "- 互信息：\n",
    "$$I(X;Y) = H(X)+H(Y)-H(X,Y)$$\n",
    "\n",
    "- 相对熵：又称KL散度，描述两个概率分布$P$和$Q$差异，用概率分布$Q$拟合真实分布$P$时，产生的信息表达损耗\n",
    "  1. 离散形式：$\\displaystyle D(P||Q) = \\sum P(x)\\log \\frac{P(x)}{Q(x)}$\n",
    "  2. 连续形式：$\\displaystyle D(P||Q) = \\int P(x)\\log \\frac{P(x)}{Q(x)}$\n",
    "\n",
    "- 交叉熵：目标与预测值之间的差距\n",
    "$$\\begin{aligned}\n",
    "D(P||Q) \n",
    "&= \\sum P(x)\\log \\frac{P(x)}{Q(x)} \\\\\n",
    "&= \\sum P(x)\\log P(x) - \\sum P(x)\\log Q(x) \\\\\n",
    "&= -H(P(x)) -\\sum P(x)\\log Q(x)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 最优化估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最小二乘估计：采用最小化误差的平方和，用于回归问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本次任务，主要介绍了人工智能的起源和发展，分为3个阶段，其主要应用于图像处理领域、语言识别领域、自然语言处理领域及综合应用；通过介绍矩阵论、概率统计、信息论、最优化估计等理论和概念，为学习后续课程建立数学基础。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
